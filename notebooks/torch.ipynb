{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_conv_block(convolution, batch_norm):\n",
    "    class ConvBlock(nn.Module):\n",
    "        def __init__(self, n_chans_in, n_chans_out, kernel_size, activation: callable, stride=1, padding=0, dilation=1):\n",
    "            super().__init__()\n",
    "            self.convolution = convolution(in_channels=n_chans_in, out_channels=n_chans_out, kernel_size=kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation, bias=False)\n",
    "            self.batch_norm = batch_norm(num_features=n_chans_out)\n",
    "            self.activation = activation\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.activation(self.batch_norm(self.convolution(input)))\n",
    "\n",
    "    return ConvBlock\n",
    "\n",
    "\n",
    "ConvBlock1d = _make_conv_block(nn.Conv1d, nn.BatchNorm1d)\n",
    "ConvBlock2d = _make_conv_block(nn.Conv2d, nn.BatchNorm2d)\n",
    "ConvBlock3d = _make_conv_block(nn.Conv3d, nn.BatchNorm3d)\n",
    "\n",
    "ConvTransposeBlock1d = _make_conv_block(nn.ConvTranspose1d, nn.BatchNorm1d)\n",
    "ConvTransposeBlock2d = _make_conv_block(nn.ConvTranspose2d, nn.BatchNorm2d)\n",
    "ConvTransposeBlock3d = _make_conv_block(nn.ConvTranspose3d, nn.BatchNorm3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_iterable_as_list(iterable):\n",
    "    return [copy_iterable_as_list(item) if hasattr(item, '__iter__') else item for item in iterable]\n",
    "\n",
    "\n",
    "def make_tnet(conv_block, conv_transposed_block):\n",
    "    class TNet(nn.Module):\n",
    "        def __init__(self, n_chans_in, n_chans_out, activation, structure, stride):\n",
    "            super().__init__()\n",
    "            assert all([len(level) == 3 for level in structure[:-1]])\n",
    "            assert len(structure[-1]) == 1\n",
    "\n",
    "            down_paths = [level[0] for level in structure[:-1]]\n",
    "            bridge_paths = [level[1] for level in structure[:-1]] + structure[-1]\n",
    "            up_paths = [level[2] for level in structure[:-1]]\n",
    "\n",
    "            down_paths[0] = [n_chans_in, *down_paths[0]]\n",
    "            bridge_paths = [[down_level[-1], *bridge_level]\n",
    "                            for down_level, bridge_level in zip(down_paths, bridge_paths)]\n",
    "\n",
    "            assert all([bridge_level[-1] < up_level[0] for bridge_level, up_level in zip(bridge_paths, up_paths)])\n",
    "\n",
    "            kernel_size = 3\n",
    "            padding = kernel_size // 2\n",
    "\n",
    "            def build_level(level):\n",
    "                return nn.Sequential(*[conv_block(n_chans_in=n_chans_in, n_chans_out=n_chans_out, padding=padding,\n",
    "                                                  kernel_size=kernel_size, activation=activation)\n",
    "                                       for n_chans_in, n_chans_out in zip(level[1:], level[:-1])])\n",
    "\n",
    "            self.down_levels = [build_level(level) for level in down_paths]\n",
    "            self.bridge_levels = [build_level(level) for level in bridge_paths]\n",
    "            self.up_levels = [build_level(level) for level in up_paths]\n",
    "\n",
    "            self.down_steps = [conv_block(n_chans_in=level[-1], n_chans_out=down_level[0], padding=padding,\n",
    "                                          kernel_size=kernel_size, stride=stride, activation=activation)\n",
    "                               for level, down_level in zip(down_paths, [*down_paths[1:], bridge_paths[-1]])]\n",
    "\n",
    "            self.up_steps = [conv_transposed_block(n_chans_in=level[-1], n_chans_out=up_level[0], padding=padding,\n",
    "                                                   kernel_size=kernel_size, stride=stride, activation=activation)\n",
    "                             for up_level, level in zip(up_paths, [*up_paths[1:], bridge_paths[-1]])]\n",
    "\n",
    "            self.output_layer = conv_block(n_chans_in=up_paths[0][-1], n_chans_out=n_chans_out, padding=padding,\n",
    "                                           kernel_size=kernel_size, stride=stride, activation=lambda x: x)\n",
    "\n",
    "        def forward(self, input):\n",
    "            print('1', flush=True)\n",
    "            down_outputs = []\n",
    "            for level, down_step in zip(self.down_levels, self.down_steps):\n",
    "                input = level(input)\n",
    "                down_outputs.append(input)\n",
    "                input = down_step(input)\n",
    "\n",
    "            print('2', flush=True)\n",
    "            bridge_outputs = [level(input) for input, level in zip([input, *down_outputs], self.bridge_levels)]\n",
    "            print('3', flush=True)\n",
    "            bottom_input = bridge_outputs[-1]\n",
    "            for bridge_output, up_step, up_level in reversed(list(zip(bridge_outputs[:-1], self.up_steps,\n",
    "                                                                      self.up_levels))):\n",
    "                bottom_input = up_level(torch.cat([bridge_output, up_step(bottom_input)], dim=1))\n",
    "            \n",
    "            print('4', flush=True)\n",
    "            return self.output_layer(bottom_input)\n",
    "\n",
    "    return TNet\n",
    "\n",
    "\n",
    "TNet2d = make_tnet(ConvBlock2d, ConvTransposeBlock2d)\n",
    "TNet3d = make_tnet(ConvBlock3d, ConvTransposeBlock3d)\n",
    "\n",
    "# register('TNet2d')(TNet2d)\n",
    "# register('TNet3d')(TNet3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [\n",
    "    [[8, 8],   [], [56, 56]],\n",
    "    [[16, 16], [], [48, 48]],\n",
    "    [[32, 32]]\n",
    "]\n",
    "\n",
    "\n",
    "tnet = TNet3d(n_chans_in=3, n_chans_out=4, activation=nn.functional.relu, structure=structure, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.from_numpy(np.ones((3, 10, 10, 10))), volatile=True)\n",
    "#tnet(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ConvBlock3d(3, 4, kernel_size=3, activation=nn.functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
