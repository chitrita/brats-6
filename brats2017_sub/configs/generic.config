train_ids = meta.from_json
    path = train_ids_path
val_ids = meta.from_json
    path = val_ids_path

experiment = experiment.flat
    makefile = "train_segm_evaluate"
    config_path = config_path
    experiment_path = experiment_path
    split = split.cv_111
        n_splits = 5
        val_size = 6
        dataset = dataset

load_x = meta.extractor
    property = "load_mscan"
    module = dataset

load_y = meta.extractor
    property = "load_segm"
    module = dataset

batch_iter_factory = batch_iter_factory.inf
    n_iters_per_batch = 100

    get_batch_iter = batch_iter.patch_3d_strat
        @init = false
        batch_size = 64
        x_patch_sizes = [[25, 25, 25], [57, 57, 57]]
        y_patch_size = [9, 9, 9]
        nonzero_fraction = 0.5
        buffer_size = 10
        ids = train_ids
        load_x = load_x
        load_y = load_y

model_core = model_core.deepmedic_orig
    n_parts = [2 2 2]
    n_chans_in = meta.extractor
        property = "n_chans_mscan"
        module = dataset

    n_chans_out = meta.extractor
        property = "n_chans_segm"
        module = dataset

predict = predict.softmax
    @init = false

model = model.model
    model_core = model_core
    predict = predict
    loss = loss.sparse_softmax_cross_entropy
        @init = false

    optimize = optimize.tf_optimize
        @init = false
        tf_optimizer_name = "MomentumOptimizer"
        use_nesterov = true
        momentum = 0.9

frozen_model = model.frozen_model
    model_core = model_core
    predict = predict

model_controller = model_controller.model_controller
    model = model
    log_path = log_path

train = train.train_segm
    @init = false

    n_epochs = 120
    lr_init = 0.1
    lr_dec_mul = 0.5
    patience = 5
    rtol = 0.03
    atol = 0.01
    model_controller = model_controller
    train_batch_iter_factory = batch_iter_factory
    val_ids = val_ids
    dataset = dataset

pred2msegm = transform.segm_prob2msegm
    @init = false
    dataset = dataset
